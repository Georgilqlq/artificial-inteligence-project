{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbf2a03",
   "metadata": {},
   "source": [
    "# Image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e322c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torch) (0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: torch==1.10.2 in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torchvision) (1.10.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torch==1.10.2->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages (from torch==1.10.2->torchvision) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\envs\\mnist_venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae218e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\mnist_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,cross_validate,train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB,BernoulliNB,CategoricalNB\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e18e3",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7482200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a picture into normalized vector with values [0,1]\n",
    "# more info here https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset\n",
    "transformer = transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "#                                transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2293a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26422272it [00:42, 619442.36it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/fashion-mnist/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 1331530.77it/s]                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/fashion-mnist/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4422656it [00:02, 1565245.36it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/fashion-mnist/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6144it [00:00, 4200457.01it/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/fashion-mnist/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./files/fashion-mnist/FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=True, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "test_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=False, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "batch_size_train= (int)(len(train_set)/10)\n",
    "batch_size_test=len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed02feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_set,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_set,\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35a0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enumerated = enumerate(train_loader)\n",
    "batch_idx, (train_x, train_y) = next(train_enumerated)\n",
    "\n",
    "test_enumerated = enumerate(test_loader)\n",
    "batch_idx, (test_x, test_y) = next(test_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d81cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f750e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(6):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(train_x[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(train_y[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ffe68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2144a4",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Comparing the models\n",
    "\n",
    "We will make a cross validation for the four models and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99591a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1bbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grouped Bar Chart for both training and validation data\n",
    "# def plot_result(x_label, y_label, plot_title, train_data, val_data):\n",
    "#         '''Function to plot a grouped bar chart showing the training and validation\n",
    "#           results of the ML model in each fold after applying K-fold cross-validation.\n",
    "#          Parameters\n",
    "#          ----------\n",
    "#          x_label: str, \n",
    "#             Name of the algorithm used for training e.g 'Decision Tree'\n",
    "          \n",
    "#          y_label: str, \n",
    "#             Name of metric being visualized e.g 'Accuracy'\n",
    "#          plot_title: str, \n",
    "#             This is the title of the plot e.g 'Accuracy Plot'\n",
    "         \n",
    "#          train_result: list, array\n",
    "#             This is the list containing either training precision, accuracy, or f1 score.\n",
    "        \n",
    "#          val_result: list, array\n",
    "#             This is the list containing either validation precision, accuracy, or f1 score.\n",
    "#          Returns\n",
    "#          -------\n",
    "#          The function returns a Grouped Barchart showing the training and validation result\n",
    "#          in each fold.\n",
    "#         '''\n",
    "        \n",
    "#         # Set size of plot\n",
    "#         plt.figure(figsize=(12,6))\n",
    "#         labels = [\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\"]\n",
    "#         X_axis = np.arange(len(labels))\n",
    "#         ax = plt.gca()\n",
    "#         plt.ylim(0.40000, 1)\n",
    "#         plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')\n",
    "#         plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')\n",
    "#         plt.title(plot_title, fontsize=30)\n",
    "#         plt.xticks(X_axis, labels)\n",
    "#         plt.xlabel(x_label, fontsize=14)\n",
    "#         plt.ylabel(y_label, fontsize=14)\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b077dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation(model, train_x, train_y, _cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f7dc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(model,X=train_x,y=train_y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb19edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbls = [\n",
    "              'gnb', \n",
    "              'mnb', \n",
    "              'cnb', \n",
    "              'bnb', \n",
    "#              'catnb',\n",
    "            ]\n",
    "\n",
    "models = {\n",
    "    'gnb': {'name': 'Gaussian Naive Bayes       ',\n",
    "           'estimator': GaussianNB(), \n",
    "           'param': [{}],\n",
    "          },\n",
    "    'mnb': {'name': 'Multinomial Naive Bayes       ',\n",
    "           'estimator': MultinomialNB(),\n",
    "           'param': [{}]\n",
    "          },\n",
    "    'cnb': {'name': 'ComplementNB   ',\n",
    "           'estimator': ComplementNB(),\n",
    "           'param': [{}],\n",
    "          },\n",
    "    'bnb':{'name': 'BernoulliNB      ',\n",
    "           'estimator': BernoulliNB(), \n",
    "           'param': [{}]\n",
    "          },\n",
    "#     'catnb':{'name': 'CategoricalNB ',\n",
    "#            'estimator': CategoricalNB(),\n",
    "#            'param': [{}]\n",
    "        \n",
    "#     }\n",
    "}\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23e6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    true_y, pred_y = test_y, model.predict(test_x)\n",
    "    print(classification_report(true_y, pred_y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90422ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_models(models):\n",
    "    results_short = {}\n",
    "    for score in scores:\n",
    "        print('='*40)\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        #'%s_macro' % score ## is a string formatting expression\n",
    "        # the parameter after % is substituted in the string placeholder %s\n",
    "        for m in model_lbls:\n",
    "            print('-'*40)\n",
    "            print(\"Trying model {}\".format(models[m]['name']))\n",
    "            clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=5,\n",
    "                               scoring='%s_macro' % score, \n",
    "    #                            iid = False, \n",
    "                               return_train_score = False,\n",
    "                               n_jobs = 2, # this allows using multi-cores\n",
    "                               )\n",
    "            clf.fit(train_x, train_y)\n",
    "            print_results(clf)\n",
    "            results_short[m] = clf.best_score_\n",
    "        print(\"Summary of results for {}\".format(score))\n",
    "        print(\"Estimator\")\n",
    "        for m in results_short.keys():\n",
    "            print(\"{}\\t - score: {:4.2}%\".format(models[m]['name'], results_short[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0060c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Gaussian Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.586 (+/-0.028) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72      1000\n",
      "           1       0.43      0.97      0.60      1000\n",
      "           2       0.58      0.39      0.47      1000\n",
      "           3       0.21      0.13      0.16      1000\n",
      "           4       0.42      0.70      0.53      1000\n",
      "           5       0.85      0.29      0.44      1000\n",
      "           6       0.30      0.04      0.07      1000\n",
      "           7       0.48      0.98      0.65      1000\n",
      "           8       0.83      0.70      0.76      1000\n",
      "           9       0.94      0.57      0.71      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.58      0.54      0.51     10000\n",
      "weighted avg       0.58      0.54      0.51     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Multinomial Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.659 (+/-0.029) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1000\n",
      "           1       0.99      0.88      0.93      1000\n",
      "           2       0.59      0.57      0.58      1000\n",
      "           3       0.66      0.87      0.75      1000\n",
      "           4       0.45      0.62      0.52      1000\n",
      "           5       0.55      0.13      0.21      1000\n",
      "           6       0.30      0.14      0.19      1000\n",
      "           7       0.60      0.91      0.72      1000\n",
      "           8       0.88      0.81      0.85      1000\n",
      "           9       0.67      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.64      0.65      0.62     10000\n",
      "weighted avg       0.64      0.65      0.62     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model ComplementNB   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.499 (+/-0.062) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70      1000\n",
      "           1       0.55      0.96      0.70      1000\n",
      "           2       0.53      0.62      0.57      1000\n",
      "           3       0.59      0.32      0.41      1000\n",
      "           4       0.44      0.49      0.46      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.61      0.86      0.71      1000\n",
      "           8       0.81      0.76      0.79      1000\n",
      "           9       0.56      0.94      0.70      1000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.47      0.58      0.50     10000\n",
      "weighted avg       0.47      0.58      0.50     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model BernoulliNB      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.709 (+/-0.023) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1000\n",
      "           1       0.94      0.90      0.92      1000\n",
      "           2       0.49      0.65      0.56      1000\n",
      "           3       0.64      0.81      0.72      1000\n",
      "           4       0.47      0.51      0.49      1000\n",
      "           5       0.98      0.67      0.80      1000\n",
      "           6       0.35      0.12      0.18      1000\n",
      "           7       0.69      0.89      0.77      1000\n",
      "           8       0.86      0.83      0.84      1000\n",
      "           9       0.82      0.87      0.84      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Summary of results for precision\n",
      "Estimator\n",
      "Gaussian Naive Bayes       \t - score: 0.59%\n",
      "Multinomial Naive Bayes       \t - score: 0.66%\n",
      "ComplementNB   \t - score:  0.5%\n",
      "BernoulliNB      \t - score: 0.71%\n",
      "========================================\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Gaussian Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.538 (+/-0.026) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72      1000\n",
      "           1       0.43      0.97      0.60      1000\n",
      "           2       0.58      0.39      0.47      1000\n",
      "           3       0.21      0.13      0.16      1000\n",
      "           4       0.42      0.70      0.53      1000\n",
      "           5       0.85      0.29      0.44      1000\n",
      "           6       0.30      0.04      0.07      1000\n",
      "           7       0.48      0.98      0.65      1000\n",
      "           8       0.83      0.70      0.76      1000\n",
      "           9       0.94      0.57      0.71      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.58      0.54      0.51     10000\n",
      "weighted avg       0.58      0.54      0.51     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Multinomial Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.666 (+/-0.024) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1000\n",
      "           1       0.99      0.88      0.93      1000\n",
      "           2       0.59      0.57      0.58      1000\n",
      "           3       0.66      0.87      0.75      1000\n",
      "           4       0.45      0.62      0.52      1000\n",
      "           5       0.55      0.13      0.21      1000\n",
      "           6       0.30      0.14      0.19      1000\n",
      "           7       0.60      0.91      0.72      1000\n",
      "           8       0.88      0.81      0.85      1000\n",
      "           9       0.67      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.64      0.65      0.62     10000\n",
      "weighted avg       0.64      0.65      0.62     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model ComplementNB   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.590 (+/-0.019) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70      1000\n",
      "           1       0.55      0.96      0.70      1000\n",
      "           2       0.53      0.62      0.57      1000\n",
      "           3       0.59      0.32      0.41      1000\n",
      "           4       0.44      0.49      0.46      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.61      0.86      0.71      1000\n",
      "           8       0.81      0.76      0.79      1000\n",
      "           9       0.56      0.94      0.70      1000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.47      0.58      0.50     10000\n",
      "weighted avg       0.47      0.58      0.50     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model BernoulliNB      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.707 (+/-0.023) for {}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1000\n",
      "           1       0.94      0.90      0.92      1000\n",
      "           2       0.49      0.65      0.56      1000\n",
      "           3       0.64      0.81      0.72      1000\n",
      "           4       0.47      0.51      0.49      1000\n",
      "           5       0.98      0.67      0.80      1000\n",
      "           6       0.35      0.12      0.18      1000\n",
      "           7       0.69      0.89      0.77      1000\n",
      "           8       0.86      0.83      0.84      1000\n",
      "           9       0.82      0.87      0.84      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "\n",
      "Summary of results for recall\n",
      "Estimator\n",
      "Gaussian Naive Bayes       \t - score: 0.54%\n",
      "Multinomial Naive Bayes       \t - score: 0.67%\n",
      "ComplementNB   \t - score: 0.59%\n",
      "BernoulliNB      \t - score: 0.71%\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972c87d",
   "metadata": {},
   "source": [
    "As we can see the Multinomial Naive Bayes and the Bernoulli Naive Bayes outperform the other two classifiers.\n",
    "That's why we will take a closer look at these two and try to pick the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca21fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'mnb': {'name': 'Multinomial Naive Bayes       ',\n",
    "           'estimator': MultinomialNB(),\n",
    "           'param': [{'alpha': [0,0.1,0.3,0.5,0.75,1,2,3,4,10,20,30,50,100],}]\n",
    "          },\n",
    "    'bnb':{'name': 'BernoulliNB      ',\n",
    "           'estimator': BernoulliNB(), \n",
    "           'param': [{'alpha': [0,0.1,0.3,0.5,0.75,1,2,3,4,10,20,30,50,100],\n",
    "\n",
    "'binarize' :[ None,0,0.1,0.3,0.5,0.75,1,2,3,4,10,20,30,50,100],\n",
    "}]\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = [\n",
    "          \n",
    "              'mnb', \n",
    "       \n",
    "              'bnb', \n",
    "#              'catnb',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54356ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Multinomial Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 30}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.659 (+/-0.030) for {'alpha': 0}\n",
      "0.660 (+/-0.028) for {'alpha': 0.1}\n",
      "0.660 (+/-0.029) for {'alpha': 0.3}\n",
      "0.660 (+/-0.029) for {'alpha': 0.5}\n",
      "0.659 (+/-0.029) for {'alpha': 0.75}\n",
      "0.659 (+/-0.029) for {'alpha': 1}\n",
      "0.659 (+/-0.029) for {'alpha': 2}\n",
      "0.663 (+/-0.032) for {'alpha': 3}\n",
      "0.664 (+/-0.033) for {'alpha': 4}\n",
      "0.671 (+/-0.039) for {'alpha': 10}\n",
      "0.678 (+/-0.027) for {'alpha': 20}\n",
      "0.680 (+/-0.020) for {'alpha': 30}\n",
      "0.674 (+/-0.029) for {'alpha': 50}\n",
      "0.601 (+/-0.052) for {'alpha': 100}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1000\n",
      "           1       0.98      0.89      0.94      1000\n",
      "           2       0.60      0.55      0.57      1000\n",
      "           3       0.65      0.88      0.75      1000\n",
      "           4       0.43      0.68      0.53      1000\n",
      "           5       0.92      0.06      0.11      1000\n",
      "           6       0.32      0.10      0.16      1000\n",
      "           7       0.57      0.94      0.71      1000\n",
      "           8       0.89      0.75      0.82      1000\n",
      "           9       0.65      0.88      0.75      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.68      0.65      0.61     10000\n",
      "weighted avg       0.68      0.65      0.61     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model BernoulliNB      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 0, 'binarize': 0.1}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.696 (+/-0.021) for {'alpha': 0, 'binarize': None}\n",
      "0.717 (+/-0.018) for {'alpha': 0, 'binarize': 0}\n",
      "0.729 (+/-0.008) for {'alpha': 0, 'binarize': 0.1}\n",
      "0.703 (+/-0.020) for {'alpha': 0, 'binarize': 0.3}\n",
      "0.665 (+/-0.022) for {'alpha': 0, 'binarize': 0.5}\n",
      "0.622 (+/-0.019) for {'alpha': 0, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 0, 'binarize': 100}\n",
      "0.695 (+/-0.021) for {'alpha': 0.1, 'binarize': None}\n",
      "0.713 (+/-0.023) for {'alpha': 0.1, 'binarize': 0}\n",
      "0.727 (+/-0.010) for {'alpha': 0.1, 'binarize': 0.1}\n",
      "0.695 (+/-0.022) for {'alpha': 0.1, 'binarize': 0.3}\n",
      "0.661 (+/-0.018) for {'alpha': 0.1, 'binarize': 0.5}\n",
      "0.624 (+/-0.020) for {'alpha': 0.1, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 0.1, 'binarize': 100}\n",
      "0.693 (+/-0.021) for {'alpha': 0.3, 'binarize': None}\n",
      "0.712 (+/-0.024) for {'alpha': 0.3, 'binarize': 0}\n",
      "0.726 (+/-0.011) for {'alpha': 0.3, 'binarize': 0.1}\n",
      "0.693 (+/-0.021) for {'alpha': 0.3, 'binarize': 0.3}\n",
      "0.660 (+/-0.020) for {'alpha': 0.3, 'binarize': 0.5}\n",
      "0.622 (+/-0.019) for {'alpha': 0.3, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 0.3, 'binarize': 100}\n",
      "0.693 (+/-0.022) for {'alpha': 0.5, 'binarize': None}\n",
      "0.711 (+/-0.024) for {'alpha': 0.5, 'binarize': 0}\n",
      "0.726 (+/-0.011) for {'alpha': 0.5, 'binarize': 0.1}\n",
      "0.693 (+/-0.021) for {'alpha': 0.5, 'binarize': 0.3}\n",
      "0.659 (+/-0.020) for {'alpha': 0.5, 'binarize': 0.5}\n",
      "0.621 (+/-0.019) for {'alpha': 0.5, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 0.5, 'binarize': 100}\n",
      "0.692 (+/-0.022) for {'alpha': 0.75, 'binarize': None}\n",
      "0.709 (+/-0.022) for {'alpha': 0.75, 'binarize': 0}\n",
      "0.726 (+/-0.012) for {'alpha': 0.75, 'binarize': 0.1}\n",
      "0.691 (+/-0.023) for {'alpha': 0.75, 'binarize': 0.3}\n",
      "0.659 (+/-0.020) for {'alpha': 0.75, 'binarize': 0.5}\n",
      "0.621 (+/-0.021) for {'alpha': 0.75, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 0.75, 'binarize': 100}\n",
      "0.691 (+/-0.023) for {'alpha': 1, 'binarize': None}\n",
      "0.709 (+/-0.023) for {'alpha': 1, 'binarize': 0}\n",
      "0.726 (+/-0.011) for {'alpha': 1, 'binarize': 0.1}\n",
      "0.691 (+/-0.023) for {'alpha': 1, 'binarize': 0.3}\n",
      "0.660 (+/-0.021) for {'alpha': 1, 'binarize': 0.5}\n",
      "0.621 (+/-0.024) for {'alpha': 1, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 1, 'binarize': 100}\n",
      "0.689 (+/-0.022) for {'alpha': 2, 'binarize': None}\n",
      "0.709 (+/-0.021) for {'alpha': 2, 'binarize': 0}\n",
      "0.723 (+/-0.011) for {'alpha': 2, 'binarize': 0.1}\n",
      "0.689 (+/-0.024) for {'alpha': 2, 'binarize': 0.3}\n",
      "0.659 (+/-0.020) for {'alpha': 2, 'binarize': 0.5}\n",
      "0.620 (+/-0.028) for {'alpha': 2, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 2, 'binarize': 100}\n",
      "0.687 (+/-0.023) for {'alpha': 3, 'binarize': None}\n",
      "0.707 (+/-0.020) for {'alpha': 3, 'binarize': 0}\n",
      "0.722 (+/-0.011) for {'alpha': 3, 'binarize': 0.1}\n",
      "0.688 (+/-0.023) for {'alpha': 3, 'binarize': 0.3}\n",
      "0.658 (+/-0.021) for {'alpha': 3, 'binarize': 0.5}\n",
      "0.619 (+/-0.028) for {'alpha': 3, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 3, 'binarize': 100}\n",
      "0.685 (+/-0.020) for {'alpha': 4, 'binarize': None}\n",
      "0.707 (+/-0.020) for {'alpha': 4, 'binarize': 0}\n",
      "0.721 (+/-0.011) for {'alpha': 4, 'binarize': 0.1}\n",
      "0.687 (+/-0.023) for {'alpha': 4, 'binarize': 0.3}\n",
      "0.658 (+/-0.021) for {'alpha': 4, 'binarize': 0.5}\n",
      "0.620 (+/-0.025) for {'alpha': 4, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 4, 'binarize': 100}\n",
      "0.681 (+/-0.022) for {'alpha': 10, 'binarize': None}\n",
      "0.703 (+/-0.019) for {'alpha': 10, 'binarize': 0}\n",
      "0.720 (+/-0.014) for {'alpha': 10, 'binarize': 0.1}\n",
      "0.686 (+/-0.028) for {'alpha': 10, 'binarize': 0.3}\n",
      "0.657 (+/-0.024) for {'alpha': 10, 'binarize': 0.5}\n",
      "0.623 (+/-0.016) for {'alpha': 10, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 10, 'binarize': 100}\n",
      "0.675 (+/-0.021) for {'alpha': 20, 'binarize': None}\n",
      "0.697 (+/-0.018) for {'alpha': 20, 'binarize': 0}\n",
      "0.716 (+/-0.016) for {'alpha': 20, 'binarize': 0.1}\n",
      "0.684 (+/-0.026) for {'alpha': 20, 'binarize': 0.3}\n",
      "0.654 (+/-0.022) for {'alpha': 20, 'binarize': 0.5}\n",
      "0.621 (+/-0.016) for {'alpha': 20, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 20, 'binarize': 100}\n",
      "0.671 (+/-0.022) for {'alpha': 30, 'binarize': None}\n",
      "0.687 (+/-0.021) for {'alpha': 30, 'binarize': 0}\n",
      "0.713 (+/-0.018) for {'alpha': 30, 'binarize': 0.1}\n",
      "0.682 (+/-0.022) for {'alpha': 30, 'binarize': 0.3}\n",
      "0.656 (+/-0.018) for {'alpha': 30, 'binarize': 0.5}\n",
      "0.627 (+/-0.012) for {'alpha': 30, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 30, 'binarize': 100}\n",
      "0.667 (+/-0.022) for {'alpha': 50, 'binarize': None}\n",
      "0.679 (+/-0.011) for {'alpha': 50, 'binarize': 0}\n",
      "0.709 (+/-0.020) for {'alpha': 50, 'binarize': 0.1}\n",
      "0.681 (+/-0.018) for {'alpha': 50, 'binarize': 0.3}\n",
      "0.653 (+/-0.021) for {'alpha': 50, 'binarize': 0.5}\n",
      "0.628 (+/-0.021) for {'alpha': 50, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 50, 'binarize': 100}\n",
      "0.657 (+/-0.024) for {'alpha': 100, 'binarize': None}\n",
      "0.667 (+/-0.009) for {'alpha': 100, 'binarize': 0}\n",
      "0.699 (+/-0.019) for {'alpha': 100, 'binarize': 0.1}\n",
      "0.676 (+/-0.024) for {'alpha': 100, 'binarize': 0.3}\n",
      "0.653 (+/-0.031) for {'alpha': 100, 'binarize': 0.5}\n",
      "0.629 (+/-0.015) for {'alpha': 100, 'binarize': 0.75}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 1}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 2}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 3}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 4}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 10}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 20}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 30}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 50}\n",
      "0.010 (+/-0.000) for {'alpha': 100, 'binarize': 100}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1000\n",
      "           1       0.97      0.89      0.93      1000\n",
      "           2       0.54      0.65      0.59      1000\n",
      "           3       0.68      0.83      0.75      1000\n",
      "           4       0.48      0.54      0.51      1000\n",
      "           5       0.94      0.76      0.84      1000\n",
      "           6       0.32      0.13      0.19      1000\n",
      "           7       0.76      0.90      0.82      1000\n",
      "           8       0.88      0.90      0.89      1000\n",
      "           9       0.88      0.89      0.89      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.71      0.73      0.71     10000\n",
      "weighted avg       0.71      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Summary of results for precision\n",
      "Estimator\n",
      "Multinomial Naive Bayes       \t - score: 0.68%\n",
      "BernoulliNB      \t - score: 0.73%\n",
      "========================================\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Multinomial Naive Bayes       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 0.3}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.667 (+/-0.024) for {'alpha': 0}\n",
      "0.667 (+/-0.024) for {'alpha': 0.1}\n",
      "0.667 (+/-0.024) for {'alpha': 0.3}\n",
      "0.667 (+/-0.024) for {'alpha': 0.5}\n",
      "0.666 (+/-0.024) for {'alpha': 0.75}\n",
      "0.666 (+/-0.024) for {'alpha': 1}\n",
      "0.665 (+/-0.024) for {'alpha': 2}\n",
      "0.667 (+/-0.024) for {'alpha': 3}\n",
      "0.666 (+/-0.023) for {'alpha': 4}\n",
      "0.663 (+/-0.025) for {'alpha': 10}\n",
      "0.660 (+/-0.020) for {'alpha': 20}\n",
      "0.657 (+/-0.019) for {'alpha': 30}\n",
      "0.652 (+/-0.019) for {'alpha': 50}\n",
      "0.643 (+/-0.021) for {'alpha': 100}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1000\n",
      "           1       0.99      0.88      0.93      1000\n",
      "           2       0.59      0.57      0.58      1000\n",
      "           3       0.66      0.87      0.75      1000\n",
      "           4       0.45      0.62      0.52      1000\n",
      "           5       0.54      0.14      0.22      1000\n",
      "           6       0.30      0.15      0.20      1000\n",
      "           7       0.60      0.91      0.72      1000\n",
      "           8       0.88      0.81      0.85      1000\n",
      "           9       0.67      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.64      0.65      0.63     10000\n",
      "weighted avg       0.64      0.65      0.63     10000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model BernoulliNB      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'alpha': 0, 'binarize': 0.1}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.698 (+/-0.020) for {'alpha': 0, 'binarize': None}\n",
      "0.718 (+/-0.016) for {'alpha': 0, 'binarize': 0}\n",
      "0.742 (+/-0.014) for {'alpha': 0, 'binarize': 0.1}\n",
      "0.715 (+/-0.019) for {'alpha': 0, 'binarize': 0.3}\n",
      "0.657 (+/-0.022) for {'alpha': 0, 'binarize': 0.5}\n",
      "0.536 (+/-0.027) for {'alpha': 0, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 0, 'binarize': 100}\n",
      "0.697 (+/-0.022) for {'alpha': 0.1, 'binarize': None}\n",
      "0.713 (+/-0.022) for {'alpha': 0.1, 'binarize': 0}\n",
      "0.739 (+/-0.011) for {'alpha': 0.1, 'binarize': 0.1}\n",
      "0.709 (+/-0.019) for {'alpha': 0.1, 'binarize': 0.3}\n",
      "0.647 (+/-0.023) for {'alpha': 0.1, 'binarize': 0.5}\n",
      "0.518 (+/-0.028) for {'alpha': 0.1, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 0.1, 'binarize': 100}\n",
      "0.697 (+/-0.022) for {'alpha': 0.3, 'binarize': None}\n",
      "0.711 (+/-0.023) for {'alpha': 0.3, 'binarize': 0}\n",
      "0.739 (+/-0.011) for {'alpha': 0.3, 'binarize': 0.1}\n",
      "0.708 (+/-0.019) for {'alpha': 0.3, 'binarize': 0.3}\n",
      "0.646 (+/-0.025) for {'alpha': 0.3, 'binarize': 0.5}\n",
      "0.516 (+/-0.029) for {'alpha': 0.3, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 0.3, 'binarize': 100}\n",
      "0.696 (+/-0.022) for {'alpha': 0.5, 'binarize': None}\n",
      "0.710 (+/-0.023) for {'alpha': 0.5, 'binarize': 0}\n",
      "0.739 (+/-0.011) for {'alpha': 0.5, 'binarize': 0.1}\n",
      "0.708 (+/-0.019) for {'alpha': 0.5, 'binarize': 0.3}\n",
      "0.645 (+/-0.024) for {'alpha': 0.5, 'binarize': 0.5}\n",
      "0.514 (+/-0.030) for {'alpha': 0.5, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 0.5, 'binarize': 100}\n",
      "0.696 (+/-0.022) for {'alpha': 0.75, 'binarize': None}\n",
      "0.708 (+/-0.022) for {'alpha': 0.75, 'binarize': 0}\n",
      "0.738 (+/-0.011) for {'alpha': 0.75, 'binarize': 0.1}\n",
      "0.706 (+/-0.021) for {'alpha': 0.75, 'binarize': 0.3}\n",
      "0.645 (+/-0.025) for {'alpha': 0.75, 'binarize': 0.5}\n",
      "0.512 (+/-0.031) for {'alpha': 0.75, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 0.75, 'binarize': 100}\n",
      "0.695 (+/-0.022) for {'alpha': 1, 'binarize': None}\n",
      "0.707 (+/-0.023) for {'alpha': 1, 'binarize': 0}\n",
      "0.737 (+/-0.011) for {'alpha': 1, 'binarize': 0.1}\n",
      "0.706 (+/-0.020) for {'alpha': 1, 'binarize': 0.3}\n",
      "0.645 (+/-0.026) for {'alpha': 1, 'binarize': 0.5}\n",
      "0.512 (+/-0.033) for {'alpha': 1, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 1, 'binarize': 100}\n",
      "0.693 (+/-0.022) for {'alpha': 2, 'binarize': None}\n",
      "0.706 (+/-0.022) for {'alpha': 2, 'binarize': 0}\n",
      "0.734 (+/-0.013) for {'alpha': 2, 'binarize': 0.1}\n",
      "0.704 (+/-0.020) for {'alpha': 2, 'binarize': 0.3}\n",
      "0.643 (+/-0.026) for {'alpha': 2, 'binarize': 0.5}\n",
      "0.508 (+/-0.032) for {'alpha': 2, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 2, 'binarize': 100}\n",
      "0.692 (+/-0.022) for {'alpha': 3, 'binarize': None}\n",
      "0.704 (+/-0.021) for {'alpha': 3, 'binarize': 0}\n",
      "0.733 (+/-0.014) for {'alpha': 3, 'binarize': 0.1}\n",
      "0.703 (+/-0.018) for {'alpha': 3, 'binarize': 0.3}\n",
      "0.642 (+/-0.025) for {'alpha': 3, 'binarize': 0.5}\n",
      "0.505 (+/-0.034) for {'alpha': 3, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 3, 'binarize': 100}\n",
      "0.690 (+/-0.019) for {'alpha': 4, 'binarize': None}\n",
      "0.703 (+/-0.019) for {'alpha': 4, 'binarize': 0}\n",
      "0.731 (+/-0.013) for {'alpha': 4, 'binarize': 0.1}\n",
      "0.702 (+/-0.018) for {'alpha': 4, 'binarize': 0.3}\n",
      "0.642 (+/-0.025) for {'alpha': 4, 'binarize': 0.5}\n",
      "0.504 (+/-0.033) for {'alpha': 4, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 4, 'binarize': 100}\n",
      "0.685 (+/-0.021) for {'alpha': 10, 'binarize': None}\n",
      "0.694 (+/-0.020) for {'alpha': 10, 'binarize': 0}\n",
      "0.726 (+/-0.014) for {'alpha': 10, 'binarize': 0.1}\n",
      "0.699 (+/-0.024) for {'alpha': 10, 'binarize': 0.3}\n",
      "0.637 (+/-0.025) for {'alpha': 10, 'binarize': 0.5}\n",
      "0.496 (+/-0.033) for {'alpha': 10, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 10, 'binarize': 100}\n",
      "0.678 (+/-0.019) for {'alpha': 20, 'binarize': None}\n",
      "0.681 (+/-0.018) for {'alpha': 20, 'binarize': 0}\n",
      "0.720 (+/-0.017) for {'alpha': 20, 'binarize': 0.1}\n",
      "0.696 (+/-0.024) for {'alpha': 20, 'binarize': 0.3}\n",
      "0.630 (+/-0.026) for {'alpha': 20, 'binarize': 0.5}\n",
      "0.484 (+/-0.031) for {'alpha': 20, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 20, 'binarize': 100}\n",
      "0.674 (+/-0.019) for {'alpha': 30, 'binarize': None}\n",
      "0.666 (+/-0.025) for {'alpha': 30, 'binarize': 0}\n",
      "0.715 (+/-0.018) for {'alpha': 30, 'binarize': 0.1}\n",
      "0.692 (+/-0.023) for {'alpha': 30, 'binarize': 0.3}\n",
      "0.627 (+/-0.026) for {'alpha': 30, 'binarize': 0.5}\n",
      "0.479 (+/-0.032) for {'alpha': 30, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 30, 'binarize': 100}\n",
      "0.667 (+/-0.020) for {'alpha': 50, 'binarize': None}\n",
      "0.648 (+/-0.025) for {'alpha': 50, 'binarize': 0}\n",
      "0.708 (+/-0.019) for {'alpha': 50, 'binarize': 0.1}\n",
      "0.688 (+/-0.022) for {'alpha': 50, 'binarize': 0.3}\n",
      "0.621 (+/-0.027) for {'alpha': 50, 'binarize': 0.5}\n",
      "0.468 (+/-0.039) for {'alpha': 50, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 50, 'binarize': 100}\n",
      "0.647 (+/-0.022) for {'alpha': 100, 'binarize': None}\n",
      "0.623 (+/-0.022) for {'alpha': 100, 'binarize': 0}\n",
      "0.690 (+/-0.017) for {'alpha': 100, 'binarize': 0.1}\n",
      "0.677 (+/-0.018) for {'alpha': 100, 'binarize': 0.3}\n",
      "0.612 (+/-0.030) for {'alpha': 100, 'binarize': 0.5}\n",
      "0.453 (+/-0.039) for {'alpha': 100, 'binarize': 0.75}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 1}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 2}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 3}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 4}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 10}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 20}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 30}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 50}\n",
      "0.100 (+/-0.000) for {'alpha': 100, 'binarize': 100}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1000\n",
      "           1       0.97      0.89      0.93      1000\n",
      "           2       0.54      0.65      0.59      1000\n",
      "           3       0.68      0.83      0.75      1000\n",
      "           4       0.48      0.54      0.51      1000\n",
      "           5       0.94      0.76      0.84      1000\n",
      "           6       0.32      0.13      0.19      1000\n",
      "           7       0.76      0.90      0.82      1000\n",
      "           8       0.88      0.90      0.89      1000\n",
      "           9       0.88      0.89      0.89      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.71      0.73      0.71     10000\n",
      "weighted avg       0.71      0.73      0.71     10000\n",
      "\n",
      "\n",
      "Summary of results for recall\n",
      "Estimator\n",
      "Multinomial Naive Bayes       \t - score: 0.67%\n",
      "BernoulliNB      \t - score: 0.74%\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcec35f",
   "metadata": {},
   "source": [
    "### Tuning the best models\n",
    "\n",
    "We will try to make a better decision abot our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01490ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores_by_parameter(model,ks,X_train,X_test,y_train,y_test,visualize=True):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for k in ks:\n",
    "        clf = model(k).fit(X_train, y_train)\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "        \n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(ks, train_scores, color='blue', label='train score')\n",
    "        plt.plot(ks, test_scores, color='green', label='test score')\n",
    "        plt.legend()\n",
    "    return train_scores,test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fc4fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c7718",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d1932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_constructor = lambda a: MultinomialNB(alpha=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3745fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6653333333333333,\n",
       "  0.6648888888888889,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6644444444444444,\n",
       "  0.6637777777777778,\n",
       "  0.6624444444444444,\n",
       "  0.662,\n",
       "  0.6615555555555556,\n",
       "  0.6591111111111111,\n",
       "  0.6555555555555556,\n",
       "  0.6531111111111111,\n",
       "  0.6455555555555555,\n",
       "  0.6326666666666667],\n",
       " [0.6713333333333333,\n",
       "  0.6726666666666666,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.6726666666666666,\n",
       "  0.672,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6733333333333333,\n",
       "  0.6693333333333333,\n",
       "  0.6653333333333333,\n",
       "  0.6593333333333333,\n",
       "  0.6573333333333333])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores_by_parameter(mnb_constructor,[0,0.1,0.3,0.5,0.75,1,2,3,4,10,20,30,50,100],X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb15f49",
   "metadata": {},
   "source": [
    "The best results are between 0 and 1. So we will try the experiment again with smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ef8b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6653333333333333,\n",
       "  0.6648888888888889,\n",
       "  0.6648888888888889,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6651111111111111,\n",
       "  0.6648888888888889,\n",
       "  0.6646666666666666,\n",
       "  0.6644444444444444,\n",
       "  0.6644444444444444,\n",
       "  0.6644444444444444,\n",
       "  0.6644444444444444,\n",
       "  0.6642222222222223,\n",
       "  0.664,\n",
       "  0.664,\n",
       "  0.6637777777777778,\n",
       "  0.6631111111111111,\n",
       "  0.6631111111111111,\n",
       "  0.6628888888888889,\n",
       "  0.6626666666666666,\n",
       "  0.6626666666666666,\n",
       "  0.6626666666666666,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6624444444444444,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.6622222222222223,\n",
       "  0.662,\n",
       "  0.6624444444444444,\n",
       "  0.6624444444444444],\n",
       " [0.6713333333333333,\n",
       "  0.672,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.6726666666666666,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672,\n",
       "  0.672])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores_by_parameter(mnb_constructor,np.arange(0,2,0.05),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores_by_parameter(mnb_constructor,np.arange(0,0.2,0.001),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7f61b",
   "metadata": {},
   "source": [
    "The best value for alpha is 0.025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f96eb",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836eada",
   "metadata": {},
   "source": [
    "Now we will do the same for BernoulliNB. From the previous experiments with the parameters we now that alpha must be around 0 and binarize around 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_by_alpha_constructor = lambda a: BernoulliNB(alpha=a,binarize=0.5)\n",
    "bnb_by_binarize_constructor = lambda b: BernoulliNB(alpha=0,binarize=b)\n",
    "bnb_constructor = lambda l: BernoulliNB(alpha=l[0],binarize=l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plot_scores_by_parameter(bnb_by_alpha_constructor,np.arange(0,2,0.05),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bb6cd",
   "metadata": {},
   "source": [
    "As we can see the best value for alpha is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b20c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plot_scores_by_parameter(bnb_by_binarize_constructor,np.arange(0,2,0.05),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plot_scores_by_parameter(bnb_by_binarize_constructor,np.arange(0,0.9,0.1),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plot_scores_by_parameter(bnb_by_binarize_constructor,np.arange(0.1,0.6,0.05),X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e588e",
   "metadata": {},
   "source": [
    "The best value for binarize is around 0.3.\n",
    "Now we will try the model with values for alpha and binarize which are close to teh already found ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[(0,0.1),(0,0.2),(0,0.3),(0,0.4),(0,0.5),(0,0.6),(0.1,0.1),(0.1,0.2),(0.1,0.3),(0.1,0.4),(0.1,0.5),(0.1,0.6)]\n",
    "train_scores,test_scores = plot_scores_by_parameter(bnb_constructor,values,X_train,X_valid,y_train,y_valid,visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value,train_score,test_score in zip(values,train_scores,test_scores):\n",
    "    print(f'alpha={value[0]} binarize={value[1]}, train score: {train_score}, test_score: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672dca5",
   "metadata": {},
   "source": [
    "This experiment confirms our previoues results. The best values are alpha=0, binarize=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a8290",
   "metadata": {},
   "source": [
    "### Final tests\n",
    "Let's test our tuned models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a59146",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha=0, binarize=0.3)\n",
    "mnb= MultinomialNB(alpha=0.025)\n",
    "\n",
    "bnb.fit(train_x,train_y)\n",
    "mnb.fit(train_x,train_y)\n",
    "# Perform the predictions\n",
    "bnb_pred = bnb.predict(test_x)\n",
    "mnb_pred = mnb.predict(test_x)\n",
    "# Calculate the accuracy of the prediction\n",
    "\n",
    "print (f'BernoulliNB Accuracy = {accuracy_score(test_y, bnb_pred)*100}')\n",
    "print (f'MultinomialNB Accuracy = {accuracy_score(test_y, mnb_pred)*100}')\n",
    "# Cross validate the scores\n",
    "\n",
    "print (f'BernoulliNB Classification Report \\n {classification_report(test_y, bnb_pred, labels=range(0,10))}')\n",
    "print (f'MultinomialNB Classification Report \\n {classification_report(test_y, mnb_pred, labels=range(0,10))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52a96f",
   "metadata": {},
   "source": [
    "BernoulliNB is the best classifier for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16ec50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b121b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3a5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a8a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_venv",
   "language": "python",
   "name": "mnist_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
