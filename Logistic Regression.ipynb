{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569b2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\nikip\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nikip\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: torch==1.13.0 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikip\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e8f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV,cross_validate,train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff937b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "train_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=True, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "test_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=False, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "batch_size_train= len(train_set)//3\n",
    "batch_size_test=len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb3048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_set,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_set,\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_enumerated = enumerate(train_loader)\n",
    "batch_idx, (train_x, train_y) = next(train_enumerated)\n",
    "\n",
    "test_enumerated = enumerate(test_loader)\n",
    "batch_idx, (test_x, test_y) = next(test_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c81333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models):\n",
    "    results_short = {}\n",
    "    for score in scores:\n",
    "        print('='*40)\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        for m in model_lbls:\n",
    "            print('-'*40)\n",
    "            print(\"Trying model {}\".format(models[m]['name']))\n",
    "            clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=5,\n",
    "                               scoring='%s_macro' % score, \n",
    "                               return_train_score = False,\n",
    "                               n_jobs = 2, \n",
    "                               )\n",
    "            clf.fit(train_x, train_y)\n",
    "            print_results(clf)\n",
    "            results_short[m] = clf.best_score_\n",
    "        print(\"Summary of results for {}\".format(score))\n",
    "        print(\"Estimator\")\n",
    "        for m in results_short.keys():\n",
    "            print(\"{}\\t - score: {:4.2}%\".format(models[m]['name'], results_short[m]))\n",
    "\n",
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    print(\"Mean test score: {}\".format(means))\n",
    "    print(\"Std test score: {}\".format(stds))\n",
    "    print(\"Params test score: {}\".format(params))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    true_y, pred_y = test_y, model.predict(test_x)\n",
    "    print(classification_report(true_y, pred_y))\n",
    "    print()\n",
    "    \n",
    "def plot_scores_by_parameter(model,ks,X_train,X_test,y_train,y_test,visualize=True):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for k in ks:\n",
    "        clf = model(k).fit(X_train, y_train)\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "        \n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(ks, train_scores, color='blue', label='train score')\n",
    "        plt.plot(ks, test_scores, color='green', label='test score')\n",
    "        plt.legend()\n",
    "    return train_scores,test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f22549",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb0e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62bd60",
   "metadata": {},
   "source": [
    "Logistic regression is linear classifier that categorizes the example as the highest probable class based on linear model of the training data. Because the linear function is unbounded, in order to get probability, the result is the put in sigmoid function that gives a number between 0 and 1. The logistic regression is binary classifier by default, but can be expanded to multi class either by one versus rest scheme or multinomial generalization.\n",
    "The latter scheme runs multiple binary regressions assuming independence of irrelevant alternatives (\"The probability of taking the car to work, rather than the bus do not depend on whether I have a bicycle\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression uses different algorithms for solving the optimization problem.\n",
    "Some solvers are limited for one versus rest schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee18397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'solver': 'saga'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.73      0.72      1000\n",
      "           3       0.83      0.85      0.84      1000\n",
      "           4       0.73      0.75      0.74      1000\n",
      "           5       0.95      0.91      0.93      1000\n",
      "           6       0.60      0.56      0.58      1000\n",
      "           7       0.90      0.94      0.92      1000\n",
      "           8       0.93      0.94      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.83      0.84      0.83     10000\n",
      "weighted avg       0.83      0.84      0.83     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression       \t - score: 0.84%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression       ',\n",
    "           'estimator': LogisticRegression(random_state=0), \n",
    "           'param': [{'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11cdc6",
   "metadata": {},
   "source": [
    "The best solver for f1 score seems to be saga. It can handle multinomial schemes as well as one versus rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b765de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'solver': 'lbfgs'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "Mean test score: [0.84595143 0.84390669 0.83968037 0.84383827 0.84240093]\n",
      "Std test score: [0.00680967 0.00641024 0.00649584 0.00655477 0.00603016]\n",
      "Params test score: [{'solver': 'lbfgs'}, {'solver': 'liblinear'}, {'solver': 'newton-cg'}, {'solver': 'newton-cholesky'}, {'solver': 'sag'}]\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.72      0.74      0.73      1000\n",
      "           3       0.83      0.85      0.84      1000\n",
      "           4       0.72      0.75      0.73      1000\n",
      "           5       0.92      0.92      0.92      1000\n",
      "           6       0.61      0.57      0.59      1000\n",
      "           7       0.91      0.92      0.92      1000\n",
      "           8       0.94      0.92      0.93      1000\n",
      "           9       0.94      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression       \t - score: 0.85%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression       ',\n",
    "           'estimator': LogisticRegression(random_state=0), \n",
    "           'param': [{'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag']}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296923e",
   "metadata": {},
   "source": [
    "The second best solver seems to be lbfgs. We will compare them along with the different schemes: multinomial and one versus rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2a8cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'multi_class': 'ovr', 'solver': 'saga'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "Mean test score: [0.84397694 0.84826809 0.84595143 0.84578108]\n",
      "Std test score: [0.00649334 0.00623359 0.00680967 0.00658662]\n",
      "Params test score: [{'multi_class': 'ovr', 'solver': 'lbfgs'}, {'multi_class': 'ovr', 'solver': 'saga'}, {'multi_class': 'multinomial', 'solver': 'lbfgs'}, {'multi_class': 'multinomial', 'solver': 'saga'}]\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.72      0.74      0.73      1000\n",
      "           3       0.82      0.86      0.84      1000\n",
      "           4       0.71      0.76      0.74      1000\n",
      "           5       0.92      0.91      0.91      1000\n",
      "           6       0.62      0.52      0.57      1000\n",
      "           7       0.91      0.93      0.92      1000\n",
      "           8       0.93      0.94      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression       \t - score: 0.85%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression       ',\n",
    "           'estimator': LogisticRegression(random_state=0), \n",
    "           'param': [{'solver': ['lbfgs', 'saga'], 'multi_class': ['ovr', 'multinomial']}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bf1e2",
   "metadata": {},
   "source": [
    "Saga beats lbfgs and one versus rest scheme seems to be the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c2142",
   "metadata": {},
   "source": [
    "The logistic regression uses regularization term to exclude extremely large values for any of the regression coefficients in the loss function. This way it can counter overfitting. Two different penalties are available: l1 and l2.\n",
    "\n",
    "L1 called also Lasso adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function.\n",
    "L2 called also Ridge regression adds the “squared magnitude” of the coefficient as the penalty term.\n",
    "Elasticnet regularization is linear combination of l1 and l2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf17a2",
   "metadata": {},
   "source": [
    "Saga solver is compatible with all penalties.\n",
    "We will compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80d57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'penalty': 'l1'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "Mean test score: [0.8443732  0.84332136        nan 0.84193589]\n",
      "Std test score: [0.00701041 0.0078915         nan 0.00749001]\n",
      "Params test score: [{'penalty': 'l1'}, {'penalty': 'l2'}, {'penalty': 'elasticnet'}, {'penalty': None}]\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.74      0.73      1000\n",
      "           3       0.82      0.87      0.84      1000\n",
      "           4       0.73      0.76      0.74      1000\n",
      "           5       0.93      0.90      0.92      1000\n",
      "           6       0.63      0.53      0.58      1000\n",
      "           7       0.90      0.93      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.83      0.84      0.84     10000\n",
      "weighted avg       0.83      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression       \t - score: 0.84%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression       ',\n",
    "           'estimator': LogisticRegression(solver='saga', multi_class='ovr'), \n",
    "           'param': [{'penalty': ['l1', 'l2', 'elasticnet', None]}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae635f43",
   "metadata": {},
   "source": [
    "Penalty l1 seems to give best results, although there is not much difference. We will try with different regularization strength. C is the inverse of the regularization strength, smaller C means stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee2ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 0.5}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "Mean test score: [       nan 0.84514973 0.84448116 0.84367096 0.8434938  0.84292958\n",
      " 0.84296878 0.84269507 0.84258409 0.84246671 0.84242669 0.84242187\n",
      " 0.84238005 0.84211274 0.84222319 0.84195481 0.84197405 0.84215416\n",
      " 0.84217911 0.84215111]\n",
      "Std test score: [       nan 0.00681315 0.00688036 0.00742467 0.00740458 0.00736772\n",
      " 0.00737918 0.00723796 0.00756026 0.00785126 0.00778168 0.00777043\n",
      " 0.00765114 0.00760023 0.00779215 0.00758156 0.00768901 0.00797297\n",
      " 0.00776743 0.00767427]\n",
      "Params test score: [{'C': 0.0}, {'C': 0.5}, {'C': 1.0}, {'C': 1.5}, {'C': 2.0}, {'C': 2.5}, {'C': 3.0}, {'C': 3.5}, {'C': 4.0}, {'C': 4.5}, {'C': 5.0}, {'C': 5.5}, {'C': 6.0}, {'C': 6.5}, {'C': 7.0}, {'C': 7.5}, {'C': 8.0}, {'C': 8.5}, {'C': 9.0}, {'C': 9.5}]\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.73      0.73      1000\n",
      "           3       0.83      0.87      0.85      1000\n",
      "           4       0.73      0.76      0.74      1000\n",
      "           5       0.93      0.90      0.91      1000\n",
      "           6       0.63      0.53      0.57      1000\n",
      "           7       0.89      0.93      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.93      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.83      0.84      0.83     10000\n",
      "weighted avg       0.83      0.84      0.83     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression\t - score: 0.85%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression',\n",
    "           'estimator': LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1), \n",
    "           'param': [{'C': np.arange(0,10, 0.5)}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca896c",
   "metadata": {},
   "source": [
    "We get best result for c = 0.5. But because the tests were for 0, 0.5, 1, ... there is possibility to get even better results for values closer to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3ab9a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Logistic Regression\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 0.7000000000000001}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "Mean test score: [0.82912841 0.84167787 0.845301   0.84556502 0.84441974]\n",
      "Std test score: [0.00693436 0.00686029 0.00676712 0.00699932 0.0072387 ]\n",
      "Params test score: [{'C': 0.1}, {'C': 0.30000000000000004}, {'C': 0.5000000000000001}, {'C': 0.7000000000000001}, {'C': 0.9000000000000001}]\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.74      0.73      1000\n",
      "           3       0.82      0.87      0.85      1000\n",
      "           4       0.73      0.76      0.75      1000\n",
      "           5       0.94      0.90      0.92      1000\n",
      "           6       0.63      0.53      0.58      1000\n",
      "           7       0.89      0.93      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.83      0.84      0.84     10000\n",
      "weighted avg       0.83      0.84      0.84     10000\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Logistic Regression\t - score: 0.85%\n"
     ]
    }
   ],
   "source": [
    "model_lbls = ['lr']\n",
    "\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression',\n",
    "           'estimator': LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1), \n",
    "           'param': [{'C': np.arange(0.1, 1, 0.2)}],\n",
    "          },\n",
    "}\n",
    "\n",
    "model_lbls = ['lr']\n",
    "scores = ['f1']\n",
    "\n",
    "evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd27bd",
   "metadata": {},
   "source": [
    "### Bagging clasifier using logistic regression\n",
    "We will try to gain better results using bagging ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40835e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35f1f3",
   "metadata": {},
   "source": [
    "Ensemble with many estimators, each on a small set of the features (taken with replacement) and trained on the whole train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c1e4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      1000\n",
      "           1       0.98      0.94      0.96      1000\n",
      "           2       0.69      0.69      0.69      1000\n",
      "           3       0.77      0.87      0.82      1000\n",
      "           4       0.69      0.74      0.72      1000\n",
      "           5       0.90      0.88      0.89      1000\n",
      "           6       0.58      0.42      0.49      1000\n",
      "           7       0.89      0.88      0.88      1000\n",
      "           8       0.90      0.94      0.92      1000\n",
      "           9       0.90      0.93      0.91      1000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg = BaggingClassifier(estimator=LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1, C = 0.7),\n",
    "                           n_estimators=20,\n",
    "                           max_features=0.1,\n",
    "                           bootstrap_features=True,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "bg.fit(train_x, train_y)\n",
    "true_y, pred_y = test_y, bg.predict(test_x)\n",
    "print(classification_report(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c63da",
   "metadata": {},
   "source": [
    "Ensemble with many estimators, trained on all features but on a small set of the data (taken with replacement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0afe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1000\n",
      "           1       0.97      0.94      0.96      1000\n",
      "           2       0.70      0.72      0.71      1000\n",
      "           3       0.79      0.87      0.83      1000\n",
      "           4       0.71      0.77      0.74      1000\n",
      "           5       0.91      0.86      0.89      1000\n",
      "           6       0.64      0.47      0.54      1000\n",
      "           7       0.88      0.89      0.88      1000\n",
      "           8       0.90      0.94      0.92      1000\n",
      "           9       0.88      0.94      0.91      1000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg = BaggingClassifier(estimator=LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1, C = 0.7),\n",
    "                           n_estimators=20,\n",
    "                           max_samples=0.1,\n",
    "                           bootstrap_features=True,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "bg.fit(train_x, train_y)\n",
    "true_y, pred_y = test_y, bg.predict(test_x)\n",
    "print(classification_report(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f3012",
   "metadata": {},
   "source": [
    "### AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101f3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46036d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.10      1.00      0.18      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(estimator=LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1, C = 0.7, random_state=0))\n",
    "\n",
    "ab.fit(train_x, train_y)\n",
    "true_y, pred_y = test_y, ab.predict(test_x)\n",
    "print(classification_report(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1223c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e3b77",
   "metadata": {},
   "source": [
    "We conclude that the best hyper parameters for the problem are:\n",
    "Solver: 'SAGA',\n",
    "Scheme: One versus Rest,\n",
    "Regularization: L1\n",
    "and inverse regularization strength C = 0.7\n",
    "\n",
    "Logistic regression does not benefit from ensemble techniques.\n",
    "Because the tests were done for 20 000 entries in the train data in order results to be consistent with the other algorithm tests we will do final test once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fc3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "train_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=True, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "test_set=torchvision.datasets.FashionMNIST('./files/fashion-mnist/', train=False, download=True,\n",
    "                             transform=transformer)\n",
    "\n",
    "batch_size_train= len(train_set)//5\n",
    "batch_size_test=len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0daab31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_set,\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_set,\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_enumerated = enumerate(train_loader)\n",
    "batch_idx, (train_x, train_y) = next(train_enumerated)\n",
    "\n",
    "test_enumerated = enumerate(test_loader)\n",
    "batch_idx, (test_x, test_y) = next(test_enumerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96463116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.71      0.72      0.72      1000\n",
      "           3       0.82      0.86      0.84      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.89      0.91      1000\n",
      "           6       0.62      0.52      0.57      1000\n",
      "           7       0.89      0.93      0.91      1000\n",
      "           8       0.92      0.94      0.93      1000\n",
      "           9       0.93      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga', multi_class='ovr', penalty='l1', n_jobs=-1, C = 0.7)\n",
    "\n",
    "lr.fit(train_x, train_y)\n",
    "true_y, pred_y = test_y, lr.predict(test_x)\n",
    "print(classification_report(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf0270",
   "metadata": {},
   "source": [
    "Logistic regression scores 83% precision and f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
